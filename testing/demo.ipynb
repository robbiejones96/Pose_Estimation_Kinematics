{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:baa72989521cf45397c90df5b07be7d9ffe64c2aebf3064639839363ec7be86e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2 as cv \n",
      "import numpy as np\n",
      "import scipy\n",
      "import PIL.Image\n",
      "import math\n",
      "import sys\n",
      "sys.path.append(\"/home/robbie/caffe_train/python\")\n",
      "import caffe\n",
      "import time\n",
      "from config_reader import config_reader\n",
      "import util\n",
      "import copy\n",
      "import matplotlib\n",
      "%matplotlib inline\n",
      "import pylab as plt\n",
      "import sys, os, random"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_test = 100\n",
      "num_models = 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#generate test images\n",
      "test_images = [None] * num_test\n",
      "for i in xrange(num_test):\n",
      "    test_image = random.choice(os.listdir('/home/robbie/data/rmppe/training/dataset/COCO/images/val2014'))\n",
      "    test_image = os.path.join('/home/robbie/data/rmppe/training/dataset/COCO/images/val2014', test_image)\n",
      "    test_images[i] = cv.imread(test_image) # B,G,R order\n",
      "caffe.set_mode_gpu()\n",
      "caffe.set_device(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lists to store averages computed by original model, which we treat as ground truth\n",
      "true_heatmap_avg = [None] * num_test\n",
      "true_paf_avg = [None] * num_test\n",
      "for i in xrange(num_models): #0 is original model\n",
      "    #we take the Euclidean distance between the average heatmap/paf computed by the smaller network vs the original\n",
      "    heatmap_loss = 0\n",
      "    paf_loss = 0\n",
      "    times = np.empty((num_test, 4))\n",
      "    param, model = config_reader(i)\n",
      "    net = caffe.Net(model['deployFile'], model['caffemodel'], caffe.TEST)\n",
      "    for j in xrange(num_test):\n",
      "        oriImg = test_images[j]\n",
      "        multiplier = [x * model['boxsize'] / oriImg.shape[0] for x in param['scale_search']]\n",
      "        heatmap_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 19))\n",
      "        paf_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 38))\n",
      "        for m in xrange(len(multiplier)):\n",
      "            scale = multiplier[m]\n",
      "            imageToTest = cv.resize(oriImg, (0,0), fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
      "            imageToTest_padded, pad = util.padRightDownCorner(imageToTest, model['stride'], model['padValue'])\n",
      "            \n",
      "            net.blobs['data'].reshape(*(1, 3, imageToTest_padded.shape[0], imageToTest_padded.shape[1]))\n",
      "            net.blobs['data'].data[...] = np.transpose(np.float32(imageToTest_padded[:,:,:,np.newaxis]), (3,2,0,1))/256 - 0.5;\n",
      "            \n",
      "            start_time = time.time()\n",
      "            output_blobs = net.forward()\n",
      "            total_time = (time.time() - start_time) * 1000\n",
      "            times[j][m] = total_time\n",
      "            \n",
      "            # extract outputs, resize, and remove padding\n",
      "            if output_blobs.keys()[1].endswith(\"L2\"): #L2 predicts heatmaps, L1 predicts PAFs\n",
      "                heatmap_index = 1\n",
      "                paf_index = 0\n",
      "            else:\n",
      "                heatmap_index = 0\n",
      "                paf_index = 1\n",
      "            heatmap = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[heatmap_index]].data), (1,2,0))\n",
      "            heatmap = cv.resize(heatmap, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
      "            heatmap = heatmap[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
      "            heatmap = cv.resize(heatmap, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n",
      "\n",
      "            paf = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[paf_index]].data), (1,2,0))\n",
      "            paf = cv.resize(paf, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
      "            paf = paf[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
      "            paf = cv.resize(paf, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n",
      "\n",
      "            heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n",
      "            paf_avg = paf_avg + paf / len(multiplier)\n",
      "        if i == 0: #original model, we just need to store computed averages\n",
      "            true_heatmap_avg[j] = heatmap_avg\n",
      "            true_paf_avg[j] = paf_avg\n",
      "        else: #compute loss\n",
      "            heatmap_loss += np.linalg.norm(true_heatmap_avg[j] - heatmap_avg)\n",
      "            paf_loss += np.linalg.norm(true_paf_avg[j] - paf_avg)\n",
      "    times = times.mean(axis=0)\n",
      "    print model['description']\n",
      "    for m in xrange(4):\n",
      "        print('At scale %d, The CNN took an average of %.2f ms.' % (m, times[m]))\n",
      "    heatmap_loss /= num_test\n",
      "    paf_loss /= num_test\n",
      "    print('Average heatmap loss: %f\\nAverage PAF loss: %f' % (heatmap_loss, paf_loss))"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "COCO Pose56 Two-level Linevec\n",
        "At scale 0, The CNN took an average of 27.53 ms.\n",
        "At scale 1, The CNN took an average of 74.95 ms.\n",
        "At scale 2, The CNN took an average of 146.63 ms.\n",
        "At scale 3, The CNN took an average of 252.18 ms.\n",
        "Average heatmap loss: 0.000000\n",
        "Average PAF loss: 0.000000\n",
        "5 stage network"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "At scale 0, The CNN took an average of 23.29 ms.\n",
        "At scale 1, The CNN took an average of 63.77 ms.\n",
        "At scale 2, The CNN took an average of 125.06 ms.\n",
        "At scale 3, The CNN took an average of 215.70 ms.\n",
        "Average heatmap loss: 31.077739\n",
        "Average PAF loss: 44.024454\n",
        "4 stage network"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "At scale 0, The CNN took an average of 19.39 ms.\n",
        "At scale 1, The CNN took an average of 52.95 ms.\n",
        "At scale 2, The CNN took an average of 104.59 ms.\n",
        "At scale 3, The CNN took an average of 180.45 ms.\n",
        "Average heatmap loss: 157.111789\n",
        "Average PAF loss: 64.825720\n",
        "3 stage network"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "At scale 0, The CNN took an average of 15.34 ms.\n",
        "At scale 1, The CNN took an average of 42.05 ms.\n",
        "At scale 2, The CNN took an average of 83.46 ms.\n",
        "At scale 3, The CNN took an average of 144.31 ms.\n",
        "Average heatmap loss: 132.253175\n",
        "Average PAF loss: 64.899015\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Let's have a closer look on those averaged heatmaps and PAFs!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(oriImg[:,:,[2,1,0]])\n",
      "plt.imshow(heatmap_avg[:,:,2], alpha=.5)\n",
      "fig = matplotlib.pyplot.gcf()\n",
      "cax = matplotlib.pyplot.gca()\n",
      "fig.set_size_inches(20, 20)\n",
      "fig.subplots_adjust(right=0.93)\n",
      "cbar_ax = fig.add_axes([0.95, 0.15, 0.01, 0.7])\n",
      "_ = fig.colorbar(ax2, cax=cbar_ax)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import ma\n",
      "U = paf_avg[:,:,16] * -1\n",
      "V = paf_avg[:,:,17]\n",
      "X, Y = np.meshgrid(np.arange(U.shape[1]), np.arange(U.shape[0]))\n",
      "M = np.zeros(U.shape, dtype='bool')\n",
      "M[U**2 + V**2 < 0.5 * 0.5] = True\n",
      "U = ma.masked_array(U, mask=M)\n",
      "V = ma.masked_array(V, mask=M)\n",
      "\n",
      "# 1\n",
      "plt.figure()\n",
      "plt.imshow(oriImg[:,:,[2,1,0]], alpha = .5)\n",
      "s = 5\n",
      "Q = plt.quiver(X[::s,::s], Y[::s,::s], U[::s,::s], V[::s,::s], \n",
      "               scale=50, headaxislength=4, alpha=.5, width=0.001, color='r')\n",
      "\n",
      "fig = matplotlib.pyplot.gcf()\n",
      "fig.set_size_inches(20, 20)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "print heatmap_avg.shape\n",
      "\n",
      "#plt.imshow(heatmap_avg[:,:,2])\n",
      "from scipy.ndimage.filters import gaussian_filter\n",
      "all_peaks = []\n",
      "peak_counter = 0\n",
      "\n",
      "for part in range(19-1):\n",
      "    x_list = []\n",
      "    y_list = []\n",
      "    map_ori = heatmap_avg[:,:,part]\n",
      "    map = gaussian_filter(map_ori, sigma=3)\n",
      "    \n",
      "    map_left = np.zeros(map.shape)\n",
      "    map_left[1:,:] = map[:-1,:]\n",
      "    map_right = np.zeros(map.shape)\n",
      "    map_right[:-1,:] = map[1:,:]\n",
      "    map_up = np.zeros(map.shape)\n",
      "    map_up[:,1:] = map[:,:-1]\n",
      "    map_down = np.zeros(map.shape)\n",
      "    map_down[:,:-1] = map[:,1:]\n",
      "    \n",
      "    peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > param['thre1']))\n",
      "    peaks = zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]) # note reverse\n",
      "    peaks_with_score = [x + (map_ori[x[1],x[0]],) for x in peaks]\n",
      "    id = range(peak_counter, peak_counter + len(peaks))\n",
      "    peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
      "\n",
      "    all_peaks.append(peaks_with_score_and_id)\n",
      "    peak_counter += len(peaks)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find connection in the specified sequence, center 29 is in the position 15\n",
      "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
      "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
      "           [1,16], [16,18], [3,17], [6,18]]\n",
      "# the middle joints heatmap correpondence\n",
      "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22], \\\n",
      "          [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], \\\n",
      "          [55,56], [37,38], [45,46]]"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": true
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connection_all = []\n",
      "special_k = []\n",
      "mid_num = 10\n",
      "\n",
      "for k in range(len(mapIdx)):\n",
      "    score_mid = paf_avg[:,:,[x-19 for x in mapIdx[k]]]\n",
      "    candA = all_peaks[limbSeq[k][0]-1]\n",
      "    candB = all_peaks[limbSeq[k][1]-1]\n",
      "    nA = len(candA)\n",
      "    nB = len(candB)\n",
      "    indexA, indexB = limbSeq[k]\n",
      "    if(nA != 0 and nB != 0):\n",
      "        connection_candidate = []\n",
      "        for i in range(nA):\n",
      "            for j in range(nB):\n",
      "                vec = np.subtract(candB[j][:2], candA[i][:2])\n",
      "                norm = math.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
      "                vec = np.divide(vec, norm)\n",
      "                \n",
      "                startend = zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), \\\n",
      "                               np.linspace(candA[i][1], candB[j][1], num=mid_num))\n",
      "                \n",
      "                vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] \\\n",
      "                                  for I in range(len(startend))])\n",
      "                vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] \\\n",
      "                                  for I in range(len(startend))])\n",
      "\n",
      "                score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
      "                score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*oriImg.shape[0]/norm-1, 0)\n",
      "                criterion1 = len(np.nonzero(score_midpts > param['thre2'])[0]) > 0.8 * len(score_midpts)\n",
      "                criterion2 = score_with_dist_prior > 0\n",
      "                if criterion1 and criterion2:\n",
      "                    connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
      "\n",
      "        connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
      "        connection = np.zeros((0,5))\n",
      "        for c in range(len(connection_candidate)):\n",
      "            i,j,s = connection_candidate[c][0:3]\n",
      "            if(i not in connection[:,3] and j not in connection[:,4]):\n",
      "                connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
      "                if(len(connection) >= min(nA, nB)):\n",
      "                    break\n",
      "\n",
      "        connection_all.append(connection)\n",
      "    else:\n",
      "        special_k.append(k)\n",
      "        connection_all.append([])"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# last number in each row is the total parts number of that person\n",
      "# the second last number in each row is the score of the overall configuration\n",
      "subset = -1 * np.ones((0, 20))\n",
      "candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
      "\n",
      "for k in range(len(mapIdx)):\n",
      "    if k not in special_k:\n",
      "        partAs = connection_all[k][:,0]\n",
      "        partBs = connection_all[k][:,1]\n",
      "        indexA, indexB = np.array(limbSeq[k]) - 1\n",
      "\n",
      "        for i in range(len(connection_all[k])): #= 1:size(temp,1)\n",
      "            found = 0\n",
      "            subset_idx = [-1, -1]\n",
      "            for j in range(len(subset)): #1:size(subset,1):\n",
      "                if subset[j][indexA] == partAs[i] or subset[j][indexB] == partBs[i]:\n",
      "                    subset_idx[found] = j\n",
      "                    found += 1\n",
      "            \n",
      "            if found == 1:\n",
      "                j = subset_idx[0]\n",
      "                if(subset[j][indexB] != partBs[i]):\n",
      "                    subset[j][indexB] = partBs[i]\n",
      "                    subset[j][-1] += 1\n",
      "                    subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
      "            elif found == 2: # if found 2 and disjoint, merge them\n",
      "                j1, j2 = subset_idx\n",
      "                print \"found = 2\"\n",
      "                membership = ((subset[j1]>=0).astype(int) + (subset[j2]>=0).astype(int))[:-2]\n",
      "                if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
      "                    subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
      "                    subset[j1][-2:] += subset[j2][-2:]\n",
      "                    subset[j1][-2] += connection_all[k][i][2]\n",
      "                    subset = np.delete(subset, j2, 0)\n",
      "                else: # as like found == 1\n",
      "                    subset[j1][indexB] = partBs[i]\n",
      "                    subset[j1][-1] += 1\n",
      "                    subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
      "\n",
      "            # if find no partA in the subset, create a new subset\n",
      "            elif not found and k < 17:\n",
      "                row = -1 * np.ones(20)\n",
      "                row[indexA] = partAs[i]\n",
      "                row[indexB] = partBs[i]\n",
      "                row[-1] = 2\n",
      "                row[-2] = sum(candidate[connection_all[k][i,:2].astype(int), 2]) + connection_all[k][i][2]\n",
      "                subset = np.vstack([subset, row])"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# delete some rows of subset which has few parts occur\n",
      "deleteIdx = [];\n",
      "for i in range(len(subset)):\n",
      "    if subset[i][-1] < 4 or subset[i][-2]/subset[i][-1] < 0.4:\n",
      "        deleteIdx.append(i)\n",
      "subset = np.delete(subset, deleteIdx, axis=0)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize\n",
      "colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
      "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
      "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
      "cmap = matplotlib.cm.get_cmap('hsv')\n",
      "\n",
      "canvas = cv.imread(test_image) # B,G,R order\n",
      "\n",
      "for i in range(18):\n",
      "    rgba = np.array(cmap(1 - i/18. - 1./36))\n",
      "    rgba[0:3] *= 255\n",
      "    for j in range(len(all_peaks[i])):\n",
      "        cv.circle(canvas, all_peaks[i][j][0:2], 4, colors[i], thickness=-1)\n",
      "\n",
      "to_plot = cv.addWeighted(oriImg, 0.3, canvas, 0.7, 0)\n",
      "plt.imshow(to_plot[:,:,[2,1,0]])\n",
      "fig = matplotlib.pyplot.gcf()\n",
      "fig.set_size_inches(12, 12)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize 2\n",
      "stickwidth = 4\n",
      "\n",
      "for i in range(17):\n",
      "    for n in range(len(subset)):\n",
      "        index = subset[n][np.array(limbSeq[i])-1]\n",
      "        if -1 in index:\n",
      "            continue\n",
      "        cur_canvas = canvas.copy()\n",
      "        Y = candidate[index.astype(int), 0]\n",
      "        X = candidate[index.astype(int), 1]\n",
      "        mX = np.mean(X)\n",
      "        mY = np.mean(Y)\n",
      "        length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
      "        angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
      "        polygon = cv.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
      "        cv.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
      "        canvas = cv.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
      "        \n",
      "plt.imshow(canvas[:,:,[2,1,0]])\n",
      "fig = matplotlib.pyplot.gcf()\n",
      "fig.set_size_inches(12, 12)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true,
      "scrolled": false
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}